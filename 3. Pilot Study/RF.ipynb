{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Don't mind about this\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "###\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.drop('CLASIFFICATION_FINAL', axis=1)\n",
    "training_label = df['CLASIFFICATION_FINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, precision_recall_curve, make_scorer, confusion_matrix\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc_score': make_scorer(roc_auc_score),\n",
    "}\n",
    "    # 'roc_curve': make_scorer(roc_curve),\n",
    "    # 'precision_recall_curve': make_scorer(precision_recall_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 31, 16, 0]\n",
      "Categories (4, int64): [0 < 16 < 31 < 51]\n"
     ]
    }
   ],
   "source": [
    "# Define the age ranges\n",
    "RF_ages = [(0, 15), (16, 30), (31, 50), (51, float('inf'))]\n",
    "RF_age_labels = [0, 16, 31, 51]\n",
    "\n",
    "# Replace values in the 'AGE' column with age ranges\n",
    "df['AGE'] = pd.cut(df['AGE'], bins=[age[0] for age in RF_ages] + [float('inf')], labels=RF_age_labels, right=False)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df['AGE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "folds = 10\n",
    "RF_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5000)\n",
    "RF_scores = cross_validate(RF_model, training_data, training_label, cv=folds, scoring=scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 0 = 0.7732075759598696\n",
      "Precision for fold 0 = 0.675380520101017\n",
      "Recall for fold 0 = 0.7573090463799174\n",
      "F1-score for fold 0 = 0.7140022368943247\n",
      "AUC for fold 0 = 0.7700038987610828\n",
      "\n",
      "\n",
      "Accuracy for fold 1 = 0.6352400389097637\n",
      "Precision for fold 1 = 0.535897823458283\n",
      "Recall for fold 1 = 0.18090208684116538\n",
      "F1-score for fold 1 = 0.2704939919893191\n",
      "AUC for fold 1 = 0.5436874125951182\n",
      "\n",
      "\n",
      "Accuracy for fold 2 = 0.6383871521486201\n",
      "Precision for fold 2 = 0.5528838208560568\n",
      "Recall for fold 2 = 0.17069748456553907\n",
      "F1-score for fold 2 = 0.26085769980506823\n",
      "AUC for fold 2 = 0.544144051451213\n",
      "\n",
      "\n",
      "Accuracy for fold 3 = 0.32838696141448437\n",
      "Precision for fold 3 = 0.20594771734217268\n",
      "Recall for fold 3 = 0.27896831470993416\n",
      "F1-score for fold 3 = 0.2369601490887815\n",
      "AUC for fold 3 = 0.3184287202547539\n",
      "\n",
      "\n",
      "Accuracy for fold 4 = 0.6784890041770776\n",
      "Precision for fold 4 = 0.6345351974491047\n",
      "Recall for fold 4 = 0.3299913260880657\n",
      "F1-score for fold 4 = 0.43418424718459964\n",
      "AUC for fold 4 = 0.608264015160999\n",
      "\n",
      "\n",
      "Accuracy for fold 5 = 0.684513194159665\n",
      "Precision for fold 5 = 0.7377380489700739\n",
      "Recall for fold 5 = 0.24212970049492322\n",
      "F1-score for fold 5 = 0.36459673856673647\n",
      "AUC for fold 5 = 0.5953714951857032\n",
      "\n",
      "\n",
      "Accuracy for fold 6 = 0.6480540164223657\n",
      "Precision for fold 6 = 0.7960764068146619\n",
      "Recall for fold 6 = 0.07867748354507884\n",
      "F1-score for fold 6 = 0.14320208023774145\n",
      "AUC for fold 6 = 0.5333228109785888\n",
      "\n",
      "\n",
      "Accuracy for fold 7 = 0.6397283920005341\n",
      "Precision for fold 7 = 0.6901257693336901\n",
      "Recall for fold 7 = 0.06579417317210062\n",
      "F1-score for fold 7 = 0.12013508792360544\n",
      "AUC for fold 7 = 0.5240787981564367\n",
      "\n",
      "\n",
      "Accuracy for fold 8 = 0.6380880627902763\n",
      "Precision for fold 8 = 0.6661346102686885\n",
      "Recall for fold 8 = 0.06388081024542068\n",
      "F1-score for fold 8 = 0.11658169797704682\n",
      "AUC for fold 8 = 0.5223834517728269\n",
      "\n",
      "\n",
      "Accuracy for fold 9 = 0.6366384695346996\n",
      "Precision for fold 9 = 0.6651597347799879\n",
      "Recall for fold 9 = 0.056305329489501746\n",
      "F1-score for fold 9 = 0.10382218040691521\n",
      "AUC for fold 9 = 0.5196924149732004\n",
      "\n",
      "\n",
      "\n",
      "Final Metrics>>\n",
      "Accuracy = 0.6300732867517357\n",
      "Precision = 0.6159879649373736\n",
      "Recall = 0.22246557555316473\n",
      "F1-score = 0.27648361100741387\n",
      "AUC = 0.5479377069289924\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(f\"Accuracy for fold {i} = {RF_scores['test_accuracy'][i]}\")\n",
    "    print(f\"Precision for fold {i} = {RF_scores['test_precision'][i]}\")\n",
    "    print(f\"Recall for fold {i} = {RF_scores['test_recall'][i]}\")\n",
    "    print(f\"F1-score for fold {i} = {RF_scores['test_f1'][i]}\")    \n",
    "    print(f\"AUC for fold {i} = {RF_scores['test_roc_auc_score'][i]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\nFinal Metrics>>\")\n",
    "print(f\"Accuracy = {sum(RF_scores['test_accuracy'])/folds}\")\n",
    "print(f\"Precision = {sum(RF_scores['test_precision'])/folds}\")\n",
    "print(f\"Recall = {sum(RF_scores['test_recall'])/folds}\")\n",
    "print(f\"F1-score = {sum(RF_scores['test_f1'])/folds}\")\n",
    "print(f\"AUC = {sum(RF_scores['test_roc_auc_score'])/folds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
